import torch
import numpy as np
from collections import Counter
import matplotlib.pyplot as plt
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForTokenClassification

# Assumed available: model, tokenizer, id_to_label, dataset (with text, input_ids, attention_mask, labels)

def compute_token_level_accuracy(dataset, model, device):
    correct, total = 0, 0
    model.eval()
    for ex in tqdm(dataset):
        input_ids = torch.tensor([ex['input_ids']]).to(device)
        attention_mask = torch.tensor([ex['attention_mask']]).to(device)
        labels = torch.tensor(ex['labels'])

        with torch.no_grad():
            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits
            preds = torch.argmax(logits, dim=-1).squeeze().cpu()

        for p, l, m in zip(preds, labels, ex['attention_mask']):
            if l != -100 and m == 1:
                total += 1
                correct += int(p == l)
    return correct / total if total > 0 else 0

def plot_label_distribution(dataset, id_to_label):
    counter = Counter()
    for ex in dataset:
        for lid in ex['labels']:
            if lid != -100:
                counter[id_to_label[lid]] += 1
    labels, counts = zip(*sorted(counter.items()))
    plt.figure()
    plt.bar(labels, counts)
    plt.xticks(rotation=90)
    plt.title("Label Distribution")
    plt.tight_layout()
    plt.show()

def compute_word_level_accuracy(dataset, model, tokenizer, id_to_label, match_type="strict"):
    correct, total = 0, 0
    model.eval()
    for ex in tqdm(dataset):
        input_ids = torch.tensor([ex['input_ids']]).to(model.device)
        attention_mask = torch.tensor([ex['attention_mask']]).to(model.device)
        labels = ex['labels']

        with torch.no_grad():
            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits
        preds = torch.argmax(logits, dim=-1).squeeze().cpu().tolist()

        tokens = tokenizer.convert_ids_to_tokens(ex['input_ids'])
        word_ids = tokenizer(ex['text'], return_offsets_mapping=True).word_ids()

        word_map = {}
        for idx, wid in enumerate(word_ids):
            if wid is not None:
                word_map.setdefault(wid, []).append(idx)

        for wid, idxs in word_map.items():
            pred_tags = [id_to_label.get(preds[i], 'O') for i in idxs if labels[i] != -100]
            true_tags = [id_to_label.get(labels[i], 'O') for i in idxs if labels[i] != -100]
            if not true_tags:
                continue
            total += 1
            if match_type == "strict":
                correct += int(pred_tags == true_tags)
            else:  # majority
                correct += int(Counter(pred_tags).most_common(1)[0][0] == Counter(true_tags).most_common(1)[0][0])
    return correct / total if total > 0 else 0

def plot_prediction_confidence(dataset, model):
    all_conf = []
    model.eval()
    for ex in tqdm(dataset):
        input_ids = torch.tensor([ex['input_ids']]).to(model.device)
        attention_mask = torch.tensor([ex['attention_mask']]).to(model.device)

        with torch.no_grad():
            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits
            probs = torch.nn.functional.softmax(logits, dim=-1).squeeze()
        for i, m in enumerate(ex['attention_mask']):
            if m == 1 and ex['labels'][i] != -100:
                all_conf.append(probs[i].max().item())

    plt.hist(all_conf, bins=20, range=(0,1))
    plt.title("Prediction Confidence Histogram")
    plt.xlabel("Confidence")
    plt.ylabel("Token Count")
    plt.show()

def sequence_level_correctness(dataset, model, id_to_label, thresholds=[0.5, 0.75, 1.0]):
    results = {t: 0 for t in thresholds}
    total = 0
    model.eval()
    for ex in tqdm(dataset):
        input_ids = torch.tensor([ex['input_ids']]).to(model.device)
        attention_mask = torch.tensor([ex['attention_mask']]).to(model.device)
        labels = ex['labels']

        with torch.no_grad():
            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits
        preds = torch.argmax(logits, dim=-1).squeeze().cpu().tolist()

        valid_pairs = [(p, l) for p, l, m in zip(preds, labels, ex['attention_mask']) if l != -100 and m == 1]
        if not valid_pairs:
            continue
        matches = sum(1 for p, l in valid_pairs if p == l)
        ratio = matches / len(valid_pairs)
        total += 1
        for t in thresholds:
            if ratio >= t:
                results[t] += 1
    return {t: results[t] / total for t in thresholds}

# Run everything
device = model.device
print("1. Token-level accuracy:", compute_token_level_accuracy(dataset, model, device))
print("2. Word-level accuracy (strict):", compute_word_level_accuracy(dataset, model, tokenizer, id_to_label, match_type="strict"))
print("3. Word-level accuracy (majority):", compute_word_level_accuracy(dataset, model, tokenizer, id_to_label, match_type="majority"))
print("4. Sequence-level correctness:", sequence_level_correctness(dataset, model, id_to_label))
print("5. Plotting label distribution:")
plot_label_distribution(dataset, id_to_label)
print("6. Plotting prediction confidence:")
plot_prediction_confidence(dataset, model)
