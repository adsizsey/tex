import torch
import pandas as pd
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def evaluate_robustness_fixed_trace(dataset, model, tokenizer, id_to_label, label_to_id, perturbation_type="None", n=5, flag_mismatches=True):

    def realistic_misspell(token):
        if token.isalpha() and len(token) > 3:
            return token[:1] + token[2] + token[1] + token[3:]
        return token

    def apply_perturbation(words, labels, perturbation_type):
        perturbed = []
        for word, label in zip(words, labels):
            if perturbation_type == "Misspelling" and "TICKER" in label:
                perturbed.append(realistic_misspell(word))
            else:
                perturbed.append(word)
        return perturbed, labels

    def tokenize_and_align_labels(words, label_ids, tokenizer, label_to_id, id_to_label):
        labels = []
        for lid in label_ids:
            if lid == -100:
                labels.append("O")
            elif isinstance(lid, str):
                labels.append(lid)
            else:
                labels.append(id_to_label[lid])

        encoding = tokenizer(words, is_split_into_words=True, return_tensors="pt", padding="max_length", truncation=True, max_length=64)
        word_ids = encoding.word_ids()
        aligned = []
        aligned_text = []
        prev_word_idx = None

        for word_idx in word_ids:
            if word_idx is None:
                aligned.append(-100)
                aligned_text.append("O")
            elif word_idx != prev_word_idx:
                label_id = label_to_id.get(labels[word_idx], label_to_id["O"])
                aligned.append(label_id)
                aligned_text.append(labels[word_idx])
            else:
                orig_label = labels[word_idx]
                if orig_label.startswith("B_"):
                    continuation = "I_" + orig_label[2:]
                    label_id = label_to_id.get(continuation, label_to_id[orig_label])
                    aligned.append(label_id)
                    aligned_text.append(continuation)
                else:
                    label_id = label_to_id.get(orig_label, label_to_id["O"])
                    aligned.append(label_id)
                    aligned_text.append(orig_label)
            prev_word_idx = word_idx

        return encoding, aligned, aligned_text

    model.eval()
    trace_rows = []
    all_preds = []
    all_trues = []

    for i in range(min(n, len(dataset))):
        sample = dataset[i]
        words = sample["text"].split()
        label_ids = sample["labels"]

        enc_orig, aligned_orig, aligned_orig_text = tokenize_and_align_labels(words, label_ids, tokenizer, label_to_id, id_to_label)
        labels_word_level = [id_to_label[l] if l != -100 else "O" for l in label_ids]
        perturbed_words, perturbed_labels = apply_perturbation(words, labels_word_level, perturbation_type)
        enc_pert, aligned_pert, _ = tokenize_and_align_labels(perturbed_words, label_ids, tokenizer, label_to_id, id_to_label)

        enc_orig = {k: v.to(model.device) for k, v in enc_orig.items()}
        enc_pert = {k: v.to(model.device) for k, v in enc_pert.items()}

        with torch.no_grad():
            pred_orig = model(**enc_orig).logits.argmax(-1).squeeze().tolist()
            pred_pert = model(**enc_pert).logits.argmax(-1).squeeze().tolist()

        toks_orig = tokenizer.convert_ids_to_tokens(enc_orig["input_ids"].squeeze())
        toks_pert = tokenizer.convert_ids_to_tokens(enc_pert["input_ids"].squeeze())

        mask = [l != -100 for l in aligned_orig]
        true_flat = [l for l in aligned_orig if l != -100]
        pred_flat = [p for p, m in zip(pred_pert, mask) if m]
        all_trues.extend(true_flat)
        all_preds.extend(pred_flat)

        mismatch_flags = [("❌" if p != t else "✅") if m else "" for p, t, m in zip(pred_pert, aligned_orig, mask)]

        trace_rows.append({
            "Sample Index": i,
            "Perturbation": perturbation_type,
            "Original Text": sample["text"],
            "Perturbed Text": " ".join(perturbed_words),
            "Original Tokens": list(toks_orig),
            "Perturbed Tokens": list(toks_pert),
            "True Labels": aligned_orig_text,  # ✅ fixed
            "Pred Orig": [id_to_label.get(p, "O") for p in pred_orig],
            "Pred Pert": [id_to_label.get(p, "O") for p in pred_pert],
            "Mismatch": mismatch_flags if flag_mismatches else None
        })

    precision, recall, f1, _ = precision_recall_fscore_support(all_trues, all_preds, average="weighted", zero_division=0)
    accuracy = accuracy_score(all_trues, all_preds)

    metrics = {
        "Accuracy": round(accuracy, 4),
        "Precision": round(precision, 4),
        "Recall": round(recall, 4),
        "F1 Score": round(f1, 4)
    }

    return pd.DataFrame(trace_rows), metrics
