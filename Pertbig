import torch
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt

def run_ner_perturbation_analysis(model, dataset_by_strategy, id_to_label, tokenizer):
    model = model.to("cpu")  # Force CPU usage
    strategy_metrics = {}

    for strategy, dataset in dataset_by_strategy.items():
        print(f"Running strategy: {strategy}")
        all_preds = []
        all_labels = []

        for example in dataset:
            inputs = tokenizer(example['text'], return_tensors="pt", truncation=True)
            inputs = {k: v.to("cpu") for k, v in inputs.items()}

            with torch.no_grad():
                logits = model(**inputs).logits

            pred_ids = torch.argmax(logits, dim=-1).squeeze().tolist()
            label_ids = example['labels']

            # Trim off CLS and SEP
            pred_ids = pred_ids[1:len(label_ids)+1]

            all_preds.extend(pred_ids)
            all_labels.extend(label_ids)

        pred_tags = [id_to_label[i] for i in all_preds]
        true_tags = [id_to_label[i] for i in all_labels]

        report = classification_report(true_tags, pred_tags, output_dict=True, zero_division=0)
        strategy_metrics[strategy] = {
            "precision": report["weighted avg"]["precision"],
            "recall": report["weighted avg"]["recall"],
            "f1": report["weighted avg"]["f1-score"],
            "accuracy": sum([p == t for p, t in zip(pred_tags, true_tags)]) / len(true_tags)
        }

    return strategy_metrics

def plot_strategy_metrics(strategy_metrics):
    strategies = list(strategy_metrics.keys())
    precision = [strategy_metrics[s]["precision"] for s in strategies]
    recall = [strategy_metrics[s]["recall"] for s in strategies]
    f1 = [strategy_metrics[s]["f1"] for s in strategies]
    acc = [strategy_metrics[s]["accuracy"] for s in strategies]

    x = range(len(strategies))
    plt.figure(figsize=(12, 6))
    plt.bar(x, precision, width=0.2, label="Precision")
    plt.bar([i + 0.2 for i in x], recall, width=0.2, label="Recall")
    plt.bar([i + 0.4 for i in x], f1, width=0.2, label="F1")
    plt.bar([i + 0.6 for i in x], acc, width=0.2, label="Accuracy")
    plt.xticks([i + 0.3 for i in x], strategies, rotation=45)
    plt.legend()
    plt.title("Token-level NER Performance under Perturbations")
    plt.tight_layout()
    plt.show()

# Usage:
# strategy_metrics = run_ner_perturbation_analysis(model, dataset_by_strategy, id_to_label, tokenizer)
# plot_strategy_metrics(strategy_metrics)
