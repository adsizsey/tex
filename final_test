import torch
import random
import re
import pandas as pd
from sklearn.metrics import precision_recall_fscore_support, accuracy_score
import matplotlib.pyplot as plt

# --- Utilities ---
def is_number(token):
    return bool(re.match(r"^\d+(\.\d+)?$", token))

def apply_perturbation_strategy(word, strategy):
    if strategy == "misspell" and len(word) > 3:
        chars = list(word)
        idx = random.randint(1, len(chars) - 2)
        chars[idx], chars[idx+1] = chars[idx+1], chars[idx]
        return "".join(chars)
    elif strategy == "insert":
        return word + "x"
    elif strategy == "combined":
        return apply_perturbation_strategy(apply_perturbation_strategy(word, "misspell"), "insert")
    else:
        return word

# --- Perturb, Tokenize, Align ---
def perturb_and_align_labels(words, labels, tokenizer, label_to_id, strategy="misspell", target="all"):
    perturbed_words = []
    perturbed_labels = []

    for word, label in zip(words, labels):
        apply = (
            target == "all" or
            ("TICKER" in label and target == "ticker") or
            (is_number(word) and target == "number")
        )
        new_word = apply_perturbation_strategy(word, strategy) if apply else word
        perturbed_words.append(new_word)
        perturbed_labels.append(label)

    tokenized = tokenizer(perturbed_words, is_split_into_words=True, return_offsets_mapping=True,
                          padding="max_length", truncation=True, return_tensors="pt")
    word_ids = tokenized.word_ids()
    tokens = tokenizer.convert_ids_to_tokens(tokenized["input_ids"][0])

    aligned_ids = []
    prev_word_idx = None
    for idx, word_idx in enumerate(word_ids):
        if word_idx is None:
            aligned_ids.append(-100)
        else:
            label = perturbed_labels[word_idx]
            if word_idx != prev_word_idx:
                aligned_ids.append(label_to_id[label])
            else:
                if label.startswith("B_"):
                    aligned_ids.append(label_to_id.get("I_" + label[2:], label_to_id["O"]))
                else:
                    aligned_ids.append(label_to_id[label])
        prev_word_idx = word_idx

    return tokenized, aligned_ids, tokens

# --- Trace Predictions ---
def trace_prediction_examples(dataset, model, tokenizer, id_to_label, label_to_id,
                              strategy="none", target="all", n=3):
    from IPython.display import display
    model.eval()

    for i in range(n):
        sample = dataset[i]
        words = sample["text"].split()
        original_ids = sample["labels"]
        original_labels = [id_to_label[l] if l != -100 else "O" for l in original_ids]

        tokenized, aligned_ids, tokens = perturb_and_align_labels(words, original_labels,
                                                                  tokenizer, label_to_id,
                                                                  strategy=strategy,
                                                                  target=target)

        input_tensor = {k: v.to(model.device) for k, v in tokenized.items() if k != "offset_mapping"}
        with torch.no_grad():
            preds = torch.argmax(model(**input_tensor).logits, dim=-1)[0].cpu().tolist()

        result_rows = []
        for j, (tok, tid, pid) in enumerate(zip(tokens, aligned_ids, preds)):
            if tok in ["[CLS]", "[SEP]", "[PAD]"] or tid == -100:
                continue
            result_rows.append({
                "Idx": j,
                "Token": tok,
                "True Label": id_to_label.get(tid, "?"),
                "Pred Label": id_to_label.get(pid, "?")
            })

        print(f"\n=== Sample {i} (strategy: {strategy}) ===")
        print("Original Text: ", " ".join(words))
        display(pd.DataFrame(result_rows))

# --- Run All Experiments ---
def run_perturbation_experiments(dataset, model, tokenizer, id_to_label, label_to_id, n_samples=100):
    configs = [
        ("none", "all"),
        ("misspell", "all"),
        ("insert", "all"),
        ("combined", "all"),
        ("misspell", "ticker"),
        ("insert", "ticker"),
        ("misspell", "number")
    ]

    results = {}
    for strategy, target in configs:
        print(f"Running: {strategy}_{target}")
        y_true_all = []
        y_pred_all = []
        for i in range(min(n_samples, len(dataset))):
            sample = dataset[i]
            words = sample["text"].split()
            original_ids = sample["labels"]
            original_labels = [id_to_label[l] if l != -100 else "O" for l in original_ids]
            encoding, aligned_ids, _ = perturb_and_align_labels(words, original_labels, tokenizer, label_to_id, strategy, target)

            input_tensor = {k: v.to(model.device) for k, v in encoding.items() if k != "offset_mapping"}
            with torch.no_grad():
                preds = torch.argmax(model(**input_tensor).logits, dim=-1)[0].cpu().tolist()

            for t, p in zip(aligned_ids, preds):
                if t != -100:
                    y_true_all.append(t)
                    y_pred_all.append(p)

        prec, recall, f1, _ = precision_recall_fscore_support(y_true_all, y_pred_all, average="weighted", zero_division=0)
        acc = accuracy_score(y_true_all, y_pred_all)
        results[f"{strategy}_{target}"] = {
            "Accuracy": round(acc, 4),
            "Precision": round(prec, 4),
            "Recall": round(recall, 4),
            "F1": round(f1, 4)
        }

    df = pd.DataFrame(results).T
    df.plot(kind="bar", figsize=(12, 6))
    plt.title("Performance under different perturbation strategies")
    plt.ylabel("Score")
    plt.ylim(0, 1)
    plt.xticks(rotation=45)
    plt.grid(True)
    plt.tight_layout()
    plt.show()
    return df
