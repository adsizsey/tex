import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
from scipy.stats import entropy
from tqdm import tqdm

def compute_text_stats(dataset, id_to_label):
    lengths_chars = []
    lengths_tokens = []
    entropy_per_sample = []

    for example in dataset:
        text = example['text']
        labels = example['labels']
        label_strs = [id_to_label[l] for l in labels if l != -100]

        lengths_chars.append(len(text))
        lengths_tokens.append(len(labels))

        label_counts = Counter(label_strs)
        label_probs = np.array(list(label_counts.values())) / sum(label_counts.values())
        ent = entropy(label_probs, base=2)
        entropy_per_sample.append(ent)

    return {
        "lengths_chars": lengths_chars,
        "lengths_tokens": lengths_tokens,
        "entropy": entropy_per_sample
    }

def plot_text_stats(stats_dict, dataset_name="Dataset"):
    plt.figure(figsize=(15, 4))

    plt.subplot(1, 3, 1)
    plt.hist(stats_dict["lengths_chars"], bins=30, color='steelblue')
    plt.title(f"{dataset_name}: Text Length (Chars)")
    plt.xlabel("Char Length")
    plt.ylabel("Freq")

    plt.subplot(1, 3, 2)
    plt.hist(stats_dict["lengths_tokens"], bins=30, color='darkorange')
    plt.title(f"{dataset_name}: Label Length (Tokens)")
    plt.xlabel("# Tokens (labels)")
    plt.ylabel("Freq")

    plt.subplot(1, 3, 3)
    plt.hist(stats_dict["entropy"], bins=30, color='mediumseagreen')
    plt.title(f"{dataset_name}: Label Diversity (Entropy)")
    plt.xlabel("Shannon Entropy")
    plt.ylabel("Freq")

    plt.tight_layout()
    plt.show()

# Example usage:
stats = compute_text_stats(test_dataset, id_to_label)
plot_text_stats(stats, dataset_name="Test Set")
