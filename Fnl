###############################################################################
# 0. GEREKLİ DEĞİŞKENLERİN VAR OLDUĞU KABUL EDİLİYOR
#    model • tokenizer • test_dataset • id_to_label • label_to_id • device
###############################################################################

import random, re, torch, numpy as np, matplotlib.pyplot as plt
from datasets import Dataset
from copy import deepcopy
from tqdm.auto import tqdm

###############################################################################
# 1. PERTURBATION FONKSİYONLARI
###############################################################################
def misspell_tickers(ex):
    words = ex["text"].split()
    for i, lid in enumerate(ex["labels"]):
        if lid != -100 and id_to_label[lid].endswith("Ticker") and len(words[i]) > 2:
            words[i] = words[i][0] + words[i][2:]
            break
    ex["text"] = " ".join(words)
    return ex

def misspell_numbers(ex):
    words = ex["text"].split()
    for i, w in enumerate(words):
        if w.replace('.','',1).isdigit() and len(w) > 2:
            words[i] = w[:-1]
            break
    ex["text"] = " ".join(words)
    return ex

def insert_words(ex, ins=("foo","bar","baz")):
    out=[]
    for w in ex["text"].split():
        out.append(w)
        if random.random() < .2:
            out.append(random.choice(ins))
    ex["text"] = " ".join(out); return ex

def combined_all(ex):
    return insert_words(misspell_numbers(misspell_tickers(ex)))

strategies = {
    "NoPerturb"      : lambda x: x,
    "MisspellTicker" : misspell_tickers,
    "MisspellNumber" : misspell_numbers,
    "InsertWords"    : insert_words,
    "CombinedAll"    : combined_all
}

###############################################################################
# 2. TOKENIZE + LABEL HİZALAMA
###############################################################################
def align(text, word_labels, max_len=128):
    tok = tokenizer(text, truncation=True, padding='max_length',
                    max_length=max_len, return_offsets_mapping=True)
    wids = tok.word_ids()
    tok["labels"] = [
        -100 if wid is None else (
            word_labels[wid] if wid < len(word_labels) else label_to_id["O"]
        )
        for wid in wids
    ]
    tok.pop("offset_mapping")
    return tok

###############################################################################
# 3. HER STRATEJİ İÇİN DATASET OLUŞTUR
###############################################################################
def build_sets(base):
    out={}
    for n,fn in strategies.items():
        print(f"→ {n}")
        pert = base.map(lambda ex: fn(deepcopy(ex)))
        cols={"input_ids":[],"attention_mask":[],"labels":[],"text":[]}
        for ex in tqdm(pert, desc=n):
            aligned = align(ex["text"], ex["labels"])
            for k in cols: cols[k].append(aligned[k] if k!="text" else ex["text"])
        out[n]=Dataset.from_dict(cols)
    return out

###############################################################################
# 4. EVALUASYON (tensor-bool mask hatası yok)
###############################################################################
def eval_set(ds):
    model.to(device).eval()
    tok_acc, samp = [], []
    loader = torch.utils.data.DataLoader(
        ds, batch_size=16, shuffle=False,
        collate_fn=lambda b:{k:[d[k] for d in b] for k in b[0]}
    )
    with torch.no_grad():
        for batch in loader:
            ids = torch.tensor(batch["input_ids"]).to(device)
            msk = torch.tensor(batch["attention_mask"]).to(device)
            true= batch["labels"]                        # list of list
            preds= model(ids,attention_mask=msk).logits.argmax(-1).cpu().tolist()
            for pv,tv in zip(preds,true):
                idx=[i for i,l in enumerate(tv) if l!=-100]
                if not idx: continue
                match=[int(pv[i]==tv[i]) for i in idx]
                score=sum(match)/len(match)
                tok_acc.append(score); samp.append(score)
    avg=lambda x: float(np.mean(x)) if x else 0.0
    pr = lambda thr: avg([s>=thr for s in samp])
    return {"token_acc":avg(tok_acc),"sample_50":pr(.5),
            "sample_70":pr(.7),"sample_90":pr(.9),"sample_100":pr(1.0)}

###############################################################################
# 5. TÜMÜNÜ ÇALIŞTIR VE ÇİZ
###############################################################################
datasets = build_sets(test_dataset)
results  = {n:eval_set(ds) for n,ds in datasets.items()}

for m in results[next(iter(results))]:
    plt.figure(figsize=(7,4))
    plt.bar(results.keys(), [results[k][m] for k in results])
    plt.title(f"{m} vs perturbasyon")
    plt.ylim(0,1); plt.xticks(rotation=25); plt.grid(axis='y',ls='--',alpha=.4)
    plt.tight_layout(); plt.show()
